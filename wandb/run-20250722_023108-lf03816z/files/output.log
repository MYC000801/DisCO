Using LocalLogger is deprecated. The constructor API will change
Total training steps: 390
/projectnb/replearn/mingyu/anaconda/envs/disco/lib/python3.10/site-packages/torch/utils/checkpoint.py:1399: FutureWarning: `torch.cpu.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cpu', args...)` instead.
  with device_autocast_ctx, torch.cpu.amp.autocast(**cpu_autocast_kwargs), recompute_context:  # type: ignore[attr-defined]
step:0 - train/loss:2.896 - train/lr(1e-3):0.000
step:1 - train/loss:2.914 - train/lr(1e-3):0.001
step:2 - train/loss:2.903 - train/lr(1e-3):0.001
step:3 - train/loss:2.920 - train/lr(1e-3):0.001
step:4 - train/loss:2.893 - train/lr(1e-3):0.001
step:5 - train/loss:2.833 - train/lr(1e-3):0.002
step:6 - train/loss:2.640 - train/lr(1e-3):0.002
step:7 - train/loss:2.614 - train/lr(1e-3):0.002
step:8 - train/loss:2.554 - train/lr(1e-3):0.002
step:9 - train/loss:2.199 - train/lr(1e-3):0.003
step:10 - train/loss:2.145 - train/lr(1e-3):0.003
step:11 - train/loss:2.113 - train/lr(1e-3):0.003
step:12 - train/loss:1.783 - train/lr(1e-3):0.003
step:13 - train/loss:1.758 - train/lr(1e-3):0.004
step:14 - train/loss:1.715 - train/lr(1e-3):0.004
step:15 - train/loss:1.675 - train/lr(1e-3):0.004
step:16 - train/loss:1.555 - train/lr(1e-3):0.004
step:17 - train/loss:1.437 - train/lr(1e-3):0.005
step:18 - train/loss:1.410 - train/lr(1e-3):0.005
step:19 - train/loss:1.396 - train/lr(1e-3):0.005
step:20 - train/loss:1.367 - train/lr(1e-3):0.005
step:21 - train/loss:1.337 - train/lr(1e-3):0.006
step:22 - train/loss:1.320 - train/lr(1e-3):0.006
step:23 - train/loss:1.278 - train/lr(1e-3):0.006
step:24 - train/loss:1.251 - train/lr(1e-3):0.006
step:25 - train/loss:1.237 - train/lr(1e-3):0.007
step:26 - train/loss:1.230 - train/lr(1e-3):0.007
step:27 - train/loss:1.221 - train/lr(1e-3):0.007
step:28 - train/loss:1.209 - train/lr(1e-3):0.007
step:29 - train/loss:1.193 - train/lr(1e-3):0.008
step:30 - train/loss:1.181 - train/lr(1e-3):0.008
step:31 - train/loss:1.168 - train/lr(1e-3):0.008
step:32 - train/loss:1.158 - train/lr(1e-3):0.008
step:33 - train/loss:1.143 - train/lr(1e-3):0.009
step:34 - train/loss:1.129 - train/lr(1e-3):0.009
step:35 - train/loss:1.113 - train/lr(1e-3):0.009
step:36 - train/loss:1.102 - train/lr(1e-3):0.009
step:37 - train/loss:1.092 - train/lr(1e-3):0.010
step:38 - train/loss:1.077 - train/lr(1e-3):0.010
step:39 - train/loss:1.060 - train/lr(1e-3):0.010
step:40 - train/loss:1.049 - train/lr(1e-3):0.010
step:41 - train/loss:1.036 - train/lr(1e-3):0.010
step:42 - train/loss:1.019 - train/lr(1e-3):0.010
step:43 - train/loss:1.006 - train/lr(1e-3):0.010
step:44 - train/loss:0.988 - train/lr(1e-3):0.010
step:45 - train/loss:0.977 - train/lr(1e-3):0.010
step:46 - train/loss:0.962 - train/lr(1e-3):0.010
step:47 - train/loss:0.948 - train/lr(1e-3):0.010
step:48 - train/loss:0.932 - train/lr(1e-3):0.010
step:49 - train/loss:0.917 - train/lr(1e-3):0.010
step:50 - train/loss:0.900 - train/lr(1e-3):0.010
step:51 - train/loss:0.883 - train/lr(1e-3):0.010
step:52 - train/loss:0.869 - train/lr(1e-3):0.010
step:53 - train/loss:0.852 - train/lr(1e-3):0.010
step:54 - train/loss:0.839 - train/lr(1e-3):0.010
step:55 - train/loss:0.823 - train/lr(1e-3):0.010
step:56 - train/loss:0.799 - train/lr(1e-3):0.010
step:57 - train/loss:0.787 - train/lr(1e-3):0.010
step:58 - train/loss:0.774 - train/lr(1e-3):0.010
step:59 - train/loss:0.761 - train/lr(1e-3):0.010
step:60 - train/loss:0.749 - train/lr(1e-3):0.010
step:61 - train/loss:0.728 - train/lr(1e-3):0.010
step:62 - train/loss:0.711 - train/lr(1e-3):0.010
step:63 - train/loss:0.698 - train/lr(1e-3):0.010
step:64 - train/loss:0.681 - train/lr(1e-3):0.010
step:65 - train/loss:0.668 - train/lr(1e-3):0.010
step:66 - train/loss:0.654 - train/lr(1e-3):0.010
step:67 - train/loss:0.638 - train/lr(1e-3):0.010
step:68 - train/loss:0.626 - train/lr(1e-3):0.010
step:69 - train/loss:0.611 - train/lr(1e-3):0.010
step:70 - train/loss:0.599 - train/lr(1e-3):0.010
step:71 - train/loss:0.581 - train/lr(1e-3):0.010
step:72 - train/loss:0.569 - train/lr(1e-3):0.010
step:73 - train/loss:0.553 - train/lr(1e-3):0.010
step:74 - train/loss:0.540 - train/lr(1e-3):0.010
step:75 - train/loss:0.525 - train/lr(1e-3):0.010
step:76 - train/loss:0.510 - train/lr(1e-3):0.010
step:77 - train/loss:0.494 - train/lr(1e-3):0.010
step:78 - train/loss:0.477 - train/lr(1e-3):0.010
step:79 - train/loss:0.466 - train/lr(1e-3):0.010
step:80 - train/loss:0.449 - train/lr(1e-3):0.010
step:81 - train/loss:0.439 - train/lr(1e-3):0.010
step:82 - train/loss:0.423 - train/lr(1e-3):0.010
step:83 - train/loss:0.405 - train/lr(1e-3):0.010
step:84 - train/loss:0.395 - train/lr(1e-3):0.010
step:85 - train/loss:0.377 - train/lr(1e-3):0.010
step:86 - train/loss:0.364 - train/lr(1e-3):0.010
step:87 - train/loss:0.352 - train/lr(1e-3):0.010
step:88 - train/loss:0.340 - train/lr(1e-3):0.010
step:89 - train/loss:0.333 - train/lr(1e-3):0.009
step:90 - train/loss:0.316 - train/lr(1e-3):0.009
step:91 - train/loss:0.303 - train/lr(1e-3):0.009
step:92 - train/loss:0.294 - train/lr(1e-3):0.009
step:93 - train/loss:0.282 - train/lr(1e-3):0.009
step:94 - train/loss:0.270 - train/lr(1e-3):0.009
step:95 - train/loss:0.258 - train/lr(1e-3):0.009
step:96 - train/loss:0.245 - train/lr(1e-3):0.009
step:97 - train/loss:0.234 - train/lr(1e-3):0.009
step:98 - train/loss:0.223 - train/lr(1e-3):0.009
step:99 - train/loss:0.217 - train/lr(1e-3):0.009
step:100 - train/loss:0.208 - train/lr(1e-3):0.009
step:101 - train/loss:0.202 - train/lr(1e-3):0.009
step:102 - train/loss:0.195 - train/lr(1e-3):0.009
step:103 - train/loss:0.183 - train/lr(1e-3):0.009
step:104 - train/loss:0.172 - train/lr(1e-3):0.009
step:105 - train/loss:0.162 - train/lr(1e-3):0.009
step:106 - train/loss:0.158 - train/lr(1e-3):0.009
step:107 - train/loss:0.146 - train/lr(1e-3):0.009
step:108 - train/loss:0.138 - train/lr(1e-3):0.009
step:109 - train/loss:0.133 - train/lr(1e-3):0.009
step:110 - train/loss:0.128 - train/lr(1e-3):0.009
step:111 - train/loss:0.119 - train/lr(1e-3):0.009
step:112 - train/loss:0.112 - train/lr(1e-3):0.009
step:113 - train/loss:0.106 - train/lr(1e-3):0.009
step:114 - train/loss:0.099 - train/lr(1e-3):0.009
step:115 - train/loss:0.101 - train/lr(1e-3):0.009
step:116 - train/loss:0.095 - train/lr(1e-3):0.009
step:117 - train/loss:0.087 - train/lr(1e-3):0.009
step:118 - train/loss:0.082 - train/lr(1e-3):0.009
step:119 - train/loss:0.078 - train/lr(1e-3):0.009
step:120 - train/loss:0.074 - train/lr(1e-3):0.009
step:121 - train/loss:0.071 - train/lr(1e-3):0.009
step:122 - train/loss:0.069 - train/lr(1e-3):0.009
step:123 - train/loss:0.063 - train/lr(1e-3):0.009
step:124 - train/loss:0.060 - train/lr(1e-3):0.009
step:125 - train/loss:0.058 - train/lr(1e-3):0.009
step:126 - train/loss:0.054 - train/lr(1e-3):0.009
step:127 - train/loss:0.051 - train/lr(1e-3):0.008
step:128 - train/loss:0.052 - train/lr(1e-3):0.008
step:129 - train/loss:0.049 - train/lr(1e-3):0.008
step:130 - train/loss:0.047 - train/lr(1e-3):0.008
step:131 - train/loss:0.043 - train/lr(1e-3):0.008
step:132 - train/loss:0.041 - train/lr(1e-3):0.008
step:133 - train/loss:0.039 - train/lr(1e-3):0.008
step:134 - train/loss:0.037 - train/lr(1e-3):0.008
step:135 - train/loss:0.035 - train/lr(1e-3):0.008
step:136 - train/loss:0.035 - train/lr(1e-3):0.008
step:137 - train/loss:0.035 - train/lr(1e-3):0.008
step:138 - train/loss:0.034 - train/lr(1e-3):0.008
step:139 - train/loss:0.032 - train/lr(1e-3):0.008
step:140 - train/loss:0.034 - train/lr(1e-3):0.008
step:141 - train/loss:0.029 - train/lr(1e-3):0.008
step:142 - train/loss:0.030 - train/lr(1e-3):0.008
step:143 - train/loss:0.029 - train/lr(1e-3):0.008
step:144 - train/loss:0.028 - train/lr(1e-3):0.008
step:145 - train/loss:0.027 - train/lr(1e-3):0.008
step:146 - train/loss:0.027 - train/lr(1e-3):0.008
step:147 - train/loss:0.026 - train/lr(1e-3):0.008
step:148 - train/loss:0.026 - train/lr(1e-3):0.008
step:149 - train/loss:0.025 - train/lr(1e-3):0.008
step:150 - train/loss:0.031 - train/lr(1e-3):0.008
step:151 - train/loss:0.026 - train/lr(1e-3):0.008
step:152 - train/loss:0.025 - train/lr(1e-3):0.008
step:153 - train/loss:0.025 - train/lr(1e-3):0.008
step:154 - train/loss:0.023 - train/lr(1e-3):0.008
step:155 - train/loss:0.024 - train/lr(1e-3):0.008
step:156 - train/loss:0.024 - train/lr(1e-3):0.007
step:157 - train/loss:0.023 - train/lr(1e-3):0.007
step:158 - train/loss:0.021 - train/lr(1e-3):0.007
step:159 - train/loss:0.022 - train/lr(1e-3):0.007
step:160 - train/loss:0.021 - train/lr(1e-3):0.007
step:161 - train/loss:0.021 - train/lr(1e-3):0.007
step:162 - train/loss:0.020 - train/lr(1e-3):0.007
step:163 - train/loss:0.022 - train/lr(1e-3):0.007
step:164 - train/loss:0.021 - train/lr(1e-3):0.007
step:165 - train/loss:0.020 - train/lr(1e-3):0.007
step:166 - train/loss:0.019 - train/lr(1e-3):0.007
step:167 - train/loss:0.018 - train/lr(1e-3):0.007
step:168 - train/loss:0.020 - train/lr(1e-3):0.007
step:169 - train/loss:0.020 - train/lr(1e-3):0.007
step:170 - train/loss:0.018 - train/lr(1e-3):0.007
step:171 - train/loss:0.020 - train/lr(1e-3):0.007
step:172 - train/loss:0.020 - train/lr(1e-3):0.007
step:173 - train/loss:0.017 - train/lr(1e-3):0.007
step:174 - train/loss:0.018 - train/lr(1e-3):0.007
step:175 - train/loss:0.018 - train/lr(1e-3):0.007
step:176 - train/loss:0.017 - train/lr(1e-3):0.007
step:177 - train/loss:0.018 - train/lr(1e-3):0.007
step:178 - train/loss:0.018 - train/lr(1e-3):0.007
step:179 - train/loss:0.018 - train/lr(1e-3):0.007
step:180 - train/loss:0.018 - train/lr(1e-3):0.006
step:181 - train/loss:0.016 - train/lr(1e-3):0.006
step:182 - train/loss:0.018 - train/lr(1e-3):0.006
step:183 - train/loss:0.018 - train/lr(1e-3):0.006
step:184 - train/loss:0.017 - train/lr(1e-3):0.006
step:185 - train/loss:0.017 - train/lr(1e-3):0.006
step:186 - train/loss:0.015 - train/lr(1e-3):0.006
step:187 - train/loss:0.018 - train/lr(1e-3):0.006
step:188 - train/loss:0.017 - train/lr(1e-3):0.006
step:189 - train/loss:0.017 - train/lr(1e-3):0.006
step:190 - train/loss:0.016 - train/lr(1e-3):0.006
step:191 - train/loss:0.016 - train/lr(1e-3):0.006
step:192 - train/loss:0.016 - train/lr(1e-3):0.006
step:193 - train/loss:0.016 - train/lr(1e-3):0.006
step:194 - train/loss:0.015 - train/lr(1e-3):0.006
step:195 - train/loss:0.015 - train/lr(1e-3):0.006
step:196 - train/loss:0.016 - train/lr(1e-3):0.006
step:197 - train/loss:0.014 - train/lr(1e-3):0.006
step:198 - train/loss:0.016 - train/lr(1e-3):0.006
step:199 - train/loss:0.016 - train/lr(1e-3):0.006
step:200 - train/loss:0.015 - train/lr(1e-3):0.006
step:201 - train/loss:0.015 - train/lr(1e-3):0.006
step:202 - train/loss:0.016 - train/lr(1e-3):0.006
step:203 - train/loss:0.016 - train/lr(1e-3):0.005
step:204 - train/loss:0.016 - train/lr(1e-3):0.005
step:205 - train/loss:0.015 - train/lr(1e-3):0.005
step:206 - train/loss:0.015 - train/lr(1e-3):0.005
step:207 - train/loss:0.014 - train/lr(1e-3):0.005
step:208 - train/loss:0.014 - train/lr(1e-3):0.005
step:209 - train/loss:0.015 - train/lr(1e-3):0.005
step:210 - train/loss:0.014 - train/lr(1e-3):0.005
step:211 - train/loss:0.013 - train/lr(1e-3):0.005
step:212 - train/loss:0.014 - train/lr(1e-3):0.005
step:213 - train/loss:0.015 - train/lr(1e-3):0.005
step:214 - train/loss:0.013 - train/lr(1e-3):0.005
step:215 - train/loss:0.014 - train/lr(1e-3):0.005
step:216 - train/loss:0.014 - train/lr(1e-3):0.005
step:217 - train/loss:0.014 - train/lr(1e-3):0.005
step:218 - train/loss:0.014 - train/lr(1e-3):0.005
step:219 - train/loss:0.015 - train/lr(1e-3):0.005
step:220 - train/loss:0.014 - train/lr(1e-3):0.005
step:221 - train/loss:0.013 - train/lr(1e-3):0.005
step:222 - train/loss:0.015 - train/lr(1e-3):0.005
step:223 - train/loss:0.014 - train/lr(1e-3):0.005
step:224 - train/loss:0.013 - train/lr(1e-3):0.005
step:225 - train/loss:0.013 - train/lr(1e-3):0.004
step:226 - train/loss:0.013 - train/lr(1e-3):0.004
step:227 - train/loss:0.014 - train/lr(1e-3):0.004
step:228 - train/loss:0.014 - train/lr(1e-3):0.004
step:229 - train/loss:0.016 - train/lr(1e-3):0.004
step:230 - train/loss:0.015 - train/lr(1e-3):0.004
step:231 - train/loss:0.015 - train/lr(1e-3):0.004
step:232 - train/loss:0.014 - train/lr(1e-3):0.004
step:233 - train/loss:0.020 - train/lr(1e-3):0.004
step:234 - train/loss:0.022 - train/lr(1e-3):0.004
step:235 - train/loss:0.017 - train/lr(1e-3):0.004
step:236 - train/loss:0.014 - train/lr(1e-3):0.004
step:237 - train/loss:0.016 - train/lr(1e-3):0.004
step:238 - train/loss:0.014 - train/lr(1e-3):0.004
step:239 - train/loss:0.014 - train/lr(1e-3):0.004
step:240 - train/loss:0.014 - train/lr(1e-3):0.004
step:241 - train/loss:0.014 - train/lr(1e-3):0.004
step:242 - train/loss:0.013 - train/lr(1e-3):0.004
step:243 - train/loss:0.013 - train/lr(1e-3):0.004
step:244 - train/loss:0.013 - train/lr(1e-3):0.004
step:245 - train/loss:0.013 - train/lr(1e-3):0.004
step:246 - train/loss:0.012 - train/lr(1e-3):0.004
step:247 - train/loss:0.015 - train/lr(1e-3):0.004
step:248 - train/loss:0.012 - train/lr(1e-3):0.003
step:249 - train/loss:0.013 - train/lr(1e-3):0.003
step:250 - train/loss:0.012 - train/lr(1e-3):0.003
step:251 - train/loss:0.014 - train/lr(1e-3):0.003
step:252 - train/loss:0.012 - train/lr(1e-3):0.003
step:253 - train/loss:0.013 - train/lr(1e-3):0.003
step:254 - train/loss:0.012 - train/lr(1e-3):0.003
step:255 - train/loss:0.012 - train/lr(1e-3):0.003
step:256 - train/loss:0.013 - train/lr(1e-3):0.003
step:257 - train/loss:0.012 - train/lr(1e-3):0.003
step:258 - train/loss:0.013 - train/lr(1e-3):0.003
step:259 - train/loss:0.012 - train/lr(1e-3):0.003
step:260 - train/loss:0.012 - train/lr(1e-3):0.003
step:261 - train/loss:0.012 - train/lr(1e-3):0.003
step:262 - train/loss:0.013 - train/lr(1e-3):0.003
step:263 - train/loss:0.012 - train/lr(1e-3):0.003
step:264 - train/loss:0.011 - train/lr(1e-3):0.003
step:265 - train/loss:0.011 - train/lr(1e-3):0.003
step:266 - train/loss:0.012 - train/lr(1e-3):0.003
step:267 - train/loss:0.012 - train/lr(1e-3):0.003
step:268 - train/loss:0.012 - train/lr(1e-3):0.003
step:269 - train/loss:0.011 - train/lr(1e-3):0.003
step:270 - train/loss:0.011 - train/lr(1e-3):0.003
step:271 - train/loss:0.012 - train/lr(1e-3):0.003
step:272 - train/loss:0.011 - train/lr(1e-3):0.003
step:273 - train/loss:0.011 - train/lr(1e-3):0.002
step:274 - train/loss:0.011 - train/lr(1e-3):0.002
step:275 - train/loss:0.012 - train/lr(1e-3):0.002
step:276 - train/loss:0.012 - train/lr(1e-3):0.002
step:277 - train/loss:0.012 - train/lr(1e-3):0.002
step:278 - train/loss:0.011 - train/lr(1e-3):0.002
step:279 - train/loss:0.011 - train/lr(1e-3):0.002
step:280 - train/loss:0.010 - train/lr(1e-3):0.002
step:281 - train/loss:0.012 - train/lr(1e-3):0.002
step:282 - train/loss:0.011 - train/lr(1e-3):0.002
step:283 - train/loss:0.011 - train/lr(1e-3):0.002
step:284 - train/loss:0.012 - train/lr(1e-3):0.002
step:285 - train/loss:0.011 - train/lr(1e-3):0.002
step:286 - train/loss:0.011 - train/lr(1e-3):0.002
step:287 - train/loss:0.011 - train/lr(1e-3):0.002
step:288 - train/loss:0.011 - train/lr(1e-3):0.002
step:289 - train/loss:0.011 - train/lr(1e-3):0.002
step:290 - train/loss:0.011 - train/lr(1e-3):0.002
step:291 - train/loss:0.011 - train/lr(1e-3):0.002
step:292 - train/loss:0.011 - train/lr(1e-3):0.002
step:293 - train/loss:0.011 - train/lr(1e-3):0.002
step:294 - train/loss:0.012 - train/lr(1e-3):0.002
step:295 - train/loss:0.011 - train/lr(1e-3):0.002
step:296 - train/loss:0.011 - train/lr(1e-3):0.002
step:297 - train/loss:0.011 - train/lr(1e-3):0.002
step:298 - train/loss:0.011 - train/lr(1e-3):0.002
step:299 - train/loss:0.011 - train/lr(1e-3):0.002
step:300 - train/loss:0.010 - train/lr(1e-3):0.002
step:301 - train/loss:0.010 - train/lr(1e-3):0.001
step:302 - train/loss:0.011 - train/lr(1e-3):0.001
step:303 - train/loss:0.011 - train/lr(1e-3):0.001
step:304 - train/loss:0.011 - train/lr(1e-3):0.001
step:305 - train/loss:0.011 - train/lr(1e-3):0.001
step:306 - train/loss:0.010 - train/lr(1e-3):0.001
step:307 - train/loss:0.010 - train/lr(1e-3):0.001
step:308 - train/loss:0.011 - train/lr(1e-3):0.001
step:309 - train/loss:0.012 - train/lr(1e-3):0.001
step:310 - train/loss:0.011 - train/lr(1e-3):0.001
step:311 - train/loss:0.011 - train/lr(1e-3):0.001
step:312 - train/loss:0.011 - train/lr(1e-3):0.001
step:313 - train/loss:0.011 - train/lr(1e-3):0.001
step:314 - train/loss:0.011 - train/lr(1e-3):0.001
step:315 - train/loss:0.010 - train/lr(1e-3):0.001
step:316 - train/loss:0.011 - train/lr(1e-3):0.001
step:317 - train/loss:0.010 - train/lr(1e-3):0.001
step:318 - train/loss:0.011 - train/lr(1e-3):0.001
step:319 - train/loss:0.011 - train/lr(1e-3):0.001
step:320 - train/loss:0.011 - train/lr(1e-3):0.001
step:321 - train/loss:0.011 - train/lr(1e-3):0.001
step:322 - train/loss:0.011 - train/lr(1e-3):0.001
step:323 - train/loss:0.011 - train/lr(1e-3):0.001
step:324 - train/loss:0.011 - train/lr(1e-3):0.001
step:325 - train/loss:0.010 - train/lr(1e-3):0.001
step:326 - train/loss:0.010 - train/lr(1e-3):0.001
step:327 - train/loss:0.010 - train/lr(1e-3):0.001
step:328 - train/loss:0.010 - train/lr(1e-3):0.001
step:329 - train/loss:0.010 - train/lr(1e-3):0.001
step:330 - train/loss:0.010 - train/lr(1e-3):0.001
step:331 - train/loss:0.010 - train/lr(1e-3):0.001
step:332 - train/loss:0.011 - train/lr(1e-3):0.001
step:333 - train/loss:0.011 - train/lr(1e-3):0.001
step:334 - train/loss:0.010 - train/lr(1e-3):0.001
step:335 - train/loss:0.010 - train/lr(1e-3):0.001
step:336 - train/loss:0.010 - train/lr(1e-3):0.001
step:337 - train/loss:0.011 - train/lr(1e-3):0.001
step:338 - train/loss:0.010 - train/lr(1e-3):0.001
step:339 - train/loss:0.010 - train/lr(1e-3):0.000
step:340 - train/loss:0.010 - train/lr(1e-3):0.000
step:341 - train/loss:0.010 - train/lr(1e-3):0.000
step:342 - train/loss:0.009 - train/lr(1e-3):0.000
step:343 - train/loss:0.010 - train/lr(1e-3):0.000
step:344 - train/loss:0.010 - train/lr(1e-3):0.000
step:345 - train/loss:0.011 - train/lr(1e-3):0.000
step:346 - train/loss:0.010 - train/lr(1e-3):0.000
step:347 - train/loss:0.010 - train/lr(1e-3):0.000
step:348 - train/loss:0.010 - train/lr(1e-3):0.000
step:349 - train/loss:0.010 - train/lr(1e-3):0.000
step:350 - train/loss:0.011 - train/lr(1e-3):0.000
step:351 - train/loss:0.010 - train/lr(1e-3):0.000
step:352 - train/loss:0.010 - train/lr(1e-3):0.000
step:353 - train/loss:0.011 - train/lr(1e-3):0.000
step:354 - train/loss:0.010 - train/lr(1e-3):0.000
step:355 - train/loss:0.011 - train/lr(1e-3):0.000
step:356 - train/loss:0.009 - train/lr(1e-3):0.000
step:357 - train/loss:0.010 - train/lr(1e-3):0.000
step:358 - train/loss:0.010 - train/lr(1e-3):0.000
step:359 - train/loss:0.010 - train/lr(1e-3):0.000
step:360 - train/loss:0.010 - train/lr(1e-3):0.000
step:361 - train/loss:0.010 - train/lr(1e-3):0.000
step:362 - train/loss:0.010 - train/lr(1e-3):0.000
step:363 - train/loss:0.010 - train/lr(1e-3):0.000
step:364 - train/loss:0.010 - train/lr(1e-3):0.000
step:365 - train/loss:0.011 - train/lr(1e-3):0.000
step:366 - train/loss:0.009 - train/lr(1e-3):0.000
step:367 - train/loss:0.010 - train/lr(1e-3):0.000
step:368 - train/loss:0.010 - train/lr(1e-3):0.000
step:369 - train/loss:0.009 - train/lr(1e-3):0.000
step:370 - train/loss:0.011 - train/lr(1e-3):0.000
step:371 - train/loss:0.010 - train/lr(1e-3):0.000
step:372 - train/loss:0.010 - train/lr(1e-3):0.000
step:373 - train/loss:0.010 - train/lr(1e-3):0.000
step:374 - train/loss:0.008 - train/lr(1e-3):0.000
step:375 - train/loss:0.010 - train/lr(1e-3):0.000
step:376 - train/loss:0.009 - train/lr(1e-3):0.000
step:377 - train/loss:0.010 - train/lr(1e-3):0.000
step:378 - train/loss:0.009 - train/lr(1e-3):0.000
step:379 - train/loss:0.010 - train/lr(1e-3):0.000
step:380 - train/loss:0.010 - train/lr(1e-3):0.000
step:381 - train/loss:0.010 - train/lr(1e-3):0.000
step:382 - train/loss:0.010 - train/lr(1e-3):0.000
step:383 - train/loss:0.009 - train/lr(1e-3):0.000
step:384 - train/loss:0.011 - train/lr(1e-3):0.000
step:385 - train/loss:0.009 - train/lr(1e-3):0.000
step:386 - train/loss:0.010 - train/lr(1e-3):0.000
step:387 - train/loss:0.009 - train/lr(1e-3):0.000
step:388 - train/loss:0.010 - train/lr(1e-3):0.000
step:389 - train/loss:0.010 - train/lr(1e-3):0.000
step:390 - val/loss:0.009
/projectnb/replearn/mingyu/anaconda/envs/disco/lib/python3.10/site-packages/torch/distributed/fsdp/fully_sharded_data_parallel.py:689: FutureWarning: FSDP.state_dict_type() and FSDP.set_state_dict_type() are being deprecated. Please use APIs, get_state_dict() and set_state_dict(), which can support different parallelisms, FSDP1, FSDP2, DDP. API doc: https://pytorch.org/docs/stable/distributed.checkpoint.html#torch.distributed.checkpoint.state_dict.get_state_dict .Tutorial: https://pytorch.org/tutorials/recipes/distributed_checkpoint_recipe.html .
  warnings.warn(
